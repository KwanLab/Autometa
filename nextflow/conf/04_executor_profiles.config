// *****************
// PROFILE SETTINGS
// control how software is used (i.e. conda, docker, etc)
// *****************

// Nextflow Autometa Pipeline Configuration.
/*
 To choose one of the available profiles (standard, cluster, chtc) you must pass
 in the the -profile argument. 
 i.e. 
 
 ```bash
 nextflow run main.nf -profile slurm 
 ```

 You may also specify multiple profiles by separating their names with a comma.
 i.e.
 
 ```bash
 nextflow run autometa.nf -profile standard,docker
 ```

 Note: Standard profile (running locally) is implictly used if no profile is specified by the user.
*/


profiles {
  
  standard {
    // https://www.nextflow.io/docs/latest/executor.html#local
    // simple profile that runs all processess locally
    
    process.executor = "local" 
  }

  basic_slurm {
    // https://www.nextflow.io/docs/latest/executor.html#slurm
    // simple profile for running jobs on slurm
    
    process.executor = "slurm"
    
    // queue is the slurm partition to use.
    // Set SLURM partition with queue directive.
    process.queue = "queue"

  }
  
  chtc {
    // https://www.nextflow.io/docs/latest/executor.html#htcondor

    process.executor = "condor"
    
    /* 
    ***IMPORTANT NOTES:***
    Please work with/discuss with CHTC staff before submitting.
    1. The pipeline must be launched from a node where the `condor_submit` command is available.
    2. The HTCondor executor for Nextflow does not support at this time the HTCondor 
    ability to transfer input/output data to the corresponding job computing node. 
    Therefore the data needs to be made accessible to the computing nodes using a 
    shared file system directory from where the Nextflow workflow has to be executed 
    (or specified via the -w option).
    */
  }
}
